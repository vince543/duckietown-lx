{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "<img src=\"../../assets/images/dtlogo.png\" alt=\"Duckietown\" width=\"50%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš™ ðŸ’» 04 - Wheel encoder based odometry\n",
    "\n",
    "\"Odometry\" is the problem of \"measuring the path\", or evolution of the pose in time, of the robot. \n",
    "\n",
    "We can solve the odometry problem by using the measurements from wheel encoders, and a so called \"dead-reckoning\" model, to estimate the evolution of the pose in time through an iterative procedure, such that:\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/odometry-1.png\" width=\"500\" alt=\"odometry-1\"></p>   \n",
    "\n",
    "$$ x_{k+1} = x_k + \\Delta x_k $$\n",
    "$$ y_{k+1} = y_k + \\Delta y_k $$\n",
    "$$ \\theta_{k+1} = \\theta_k + \\Delta \\theta_k $$\n",
    "\n",
    "Where initial conditions ($x_0$, $y_0$, $\\theta_0$) are assumed to be known. The increments can be calculated by:\n",
    "\n",
    "1. **Determining the rotation of each wheel through the wheel encoder mesurements**\n",
    "\n",
    "$$\\Delta \\phi_k = N_k \\cdot \\alpha$$\n",
    "\n",
    "where $N_k$ is the number of pulses, or \"ticks\", measured from the encoders in the $k-th$ time interval, $\\alpha = \\frac{2 \\pi}{N_{tot}}$ is the rotation per tick, and $N_{tot}$ the total number of ticks per revolution ($N_{tot} = 135$ for the wheel encoders we will be using). This relation is evaluated for each wheel, yielding $\\Delta \\phi_{l,k}$ and $\\Delta \\phi_{r,k}$ for the left and right wheels respectively.\n",
    "\n",
    "2. **Deriving the total distance travelled by each wheel**\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/odometry-d.png\" width=\"250\" alt=\"odometry-d\"></p> \n",
    "\n",
    "Assuming the wheel radii are the same (equal to $R$) for both wheels, the distance travelled by each wheel is given by:\n",
    "\n",
    "$$ d_{l/r, k} = R \\cdot \\Delta \\phi_{l/r,k}$$\n",
    "\n",
    "3. **Finding the rotation and distance travelled by the robot (frame)**\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/odometry-2.png\" width=\"250\" alt=\"odometry-2\"></p>    \n",
    "\n",
    "Under the assumption of no slipping of the robot wheels, we can derive the distance travelled by the origin of the robot frame (point $A$) and the rotation of the robot $\\Delta \\theta$:\n",
    "\n",
    "$$ d_{A, k} = \\frac{d_{r,k} + d_{l,k}}{2} $$\n",
    "$$ \\Delta \\theta_{k} = \\frac{d_{r,k} - d_{l,k}}{2L}$$\n",
    "\n",
    "4. **Expressing the robot motion in the world reference frame**\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/odometry-3.png\" width=\"250\" alt=\"odometry-3\"></p>\n",
    "\n",
    "Finally, we can express the estimated motion in the world reference frame and find:\n",
    "\n",
    "$$ \\Delta x_k = d_{A, k} \\cos\\theta_k $$\n",
    "$$ \\Delta y_k = d_{A, k} \\sin\\theta_k $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš™ ðŸ’» Let's get started!\n",
    "\n",
    "In this activity you will write a function that produces an estimate of the pose of the Duckiebot, given mesurements from the wheel encoders and an initial position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run and do not edit this magic cell. \n",
    "# It helps getting things to work throughout the Jupyter notebook - in particular importing changes in functions made in files other than this workspace.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x0 = y0 = 0.0 # meters\n",
    "theta0 = np.deg2rad(0) # radians\n",
    "\n",
    "print(x0,y0, theta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determining the rotation of each wheel through the wheel encoder mesurements\n",
    "\n",
    "We have seen how to read wheel encoder data in the [wheel encoder tutorial](../../notebooks/03-Wheel-Encoders-Tutorial/wheel_encoders_tutorial.ipynb). We can now use this data to measure the rotation of each wheel. \n",
    "\n",
    "### Wheel encoder calibration factor\n",
    "\n",
    "Remember that there are 135 ticks per revolution on the wheel encoders we are using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The angular resolution of our encoders is: 2.6666666666666665 degrees\n"
     ]
    }
   ],
   "source": [
    "# Write the correct expressions \n",
    "import numpy as np \n",
    "\n",
    "N_tot = 135 # total number of ticks per revolution\n",
    "alpha = 2 * np.pi / N_tot # wheel rotation per tick in radians\n",
    "\n",
    "print(f\"The angular resolution of our encoders is: {np.rad2deg(alpha)} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that at the current update the left and right motor encoders have produced the following measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to play with the numbers to get an idea of the expected outcome\n",
    "\n",
    "ticks_left = 1\n",
    "prev_tick_left = 0\n",
    "\n",
    "ticks_right = 0\n",
    "prev_tick_right = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much did each wheel rotate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The left wheel rotated: 13.333333333333334 degrees\n",
      "The right wheel rotated: 13.333333333333334 degrees\n"
     ]
    }
   ],
   "source": [
    "# How much would the wheels rotate with the above tick measurements? \n",
    "\n",
    "# Repetita iuvant: don't confuse degrees and radians when expressing angles\n",
    "# Machines always use radians, humans make sense of degrees better. \n",
    "# Mixing these up is a very very common source of error!\n",
    "\n",
    "delta_ticks_left = 5 # delta ticks of left wheel \n",
    "delta_ticks_right = 5 # delta ticks of right wheel \n",
    "rotation_wheel_left = alpha*delta_ticks_left # total rotation of left wheel in rad\n",
    "rotation_wheel_right = alpha*delta_ticks_right # total rotation of right wheel in rad\n",
    "\n",
    "print(f\"The left wheel rotated: {np.rad2deg(rotation_wheel_left)} degrees\")\n",
    "print(f\"The right wheel rotated: {np.rad2deg(rotation_wheel_right)} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ðŸš™ ðŸ’» Evaluate distance travelled by each wheel\n",
    "\n",
    "Now let's calculate the distance travelled by each wheel. It depends on the wheel radii. We need to determine them! We could use advanced odometry calibration procedures, but let's take it a step at the time. \n",
    "\n",
    "If you have a robot, take a ruler and measure your wheel radii (let's assume they are the same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the radius of your wheels (assuming they are identical)? \n",
    "\n",
    "R = 0.0335 # insert value measured by ruler (meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the default value used in simulation and on the robot is $R = 0.0318 \\text{m}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The left wheel travelled: 0.007795803992241339 meters\n",
      "The right wheel rotated: 0.007795803992241339 meters\n"
     ]
    }
   ],
   "source": [
    "# What is the distance travelled by each wheel?\n",
    "\n",
    "d_left = R*rotation_wheel_left\n",
    "d_right = R*rotation_wheel_right\n",
    "\n",
    "print(f\"The left wheel travelled: {d_left} meters\")\n",
    "print(f\"The right wheel rotated: {d_right} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš™ Save your new value of `R`\n",
    "\n",
    "If you have a Duckiebot, let's make sure it remembers its new wheel radius! You should already know how to do this from [wheel calibration tutorial](../02-Wheel-Calibration/wheels_calibration.ipynb). \n",
    "\n",
    "Power you Duckiebot on, make sure it is connected to the network and you can ping it, then open a terminal **on your computer** and type:\n",
    "\n",
    "    dts start_gui_tools ROBOTNAME\n",
    "    \n",
    "    rosparam set /ROBOTNAME/kinematics_node/radius R-value\n",
    "    \n",
    "where `R-value` is the value of the wheel radius you measured (expressed in meters). You can then save it with: \n",
    "\n",
    "    rosservice call /ROBOTNAME/kinematics_node/save_calibration\n",
    "    \n",
    "and finally verify that it has been saved by opening the `ROBOTNAME.yaml` file in your Dashboard > File Manager > Calibrations > Kinematics page.\n",
    "\n",
    "You can keep the terminal you just used open, so we can save the baseline measurement too. Let's keep going!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ðŸš™ ðŸ’» Find the rotation and distance travelled by the Duckiebot\n",
    "\n",
    "If you have previoulsy set your robot's gain so that the wheels do not slip, the travelled distance of point $A$ (origin of the robot frame) will be given by the average of the distances travelled by the wheels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robot has travelled: 0.007795803992241339 meters\n"
     ]
    }
   ],
   "source": [
    "# How much has the robot travelled? \n",
    "\n",
    "d_A = (d_left + d_right)/2 # robot distance travelled in robot frame (meters)\n",
    "\n",
    "print(f\"The robot has travelled: {d_A} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the rotation of the robot we need to measure the baseline too - or the distance between the center of the two wheels: \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/odometry-baseline.png\" width=\"300\" alt=\"odometry-baseline\"></p>  \n",
    "\n",
    "If you have a robot, take a ruler and measure it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the baseline length of your robot? \n",
    "\n",
    "baseline_wheel2wheel = 0.099 #  Take a ruler and measure the distance between the center of the two wheels (meters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the default value, and that used in simulation, is $baseline = 0.1m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to calculate the rotation of the Duckiebot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The robot has rotated: 0.0 degrees\n"
     ]
    }
   ],
   "source": [
    "# Of what angle has the robot rotated? \n",
    "\n",
    "Delta_Theta = (d_right - d_left)/baseline_wheel2wheel # [radians]\n",
    "\n",
    "print(f\"The robot has rotated: {np.rad2deg(Delta_Theta)} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš™ Save your new value of `baseline`\n",
    "\n",
    "Let's make sure it remembers its new wheel baseline! You should already know how to do this from [wheel calibration tutorial](../02-Wheel-Calibration/wheels_calibration.ipynb). \n",
    "\n",
    "Power you Duckiebot on, make sure it is connected to the network and you can ping it, then open a terminal **on your computer** and type:\n",
    "\n",
    "    dts start_gui_tools ROBOTNAME\n",
    "    \n",
    "    rosparam set /ROBOTNAME/kinematics_node/baseline baseline-value\n",
    "    \n",
    "where `baseline-value` is the value of `baseline_wheel2wheel` you just measured (expressed in meters). You can then save it with: \n",
    "\n",
    "    rosservice call /ROBOTNAME/kinematics_node/save_calibration\n",
    "    \n",
    "and finally verify that it has been saved by opening the `ROBOTNAME.yaml` file in your Dashboard > File Manager > Calibrations > Kinematics page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "# ðŸ’» ðŸš™ Write the odometry function\n",
    "\n",
    "We have been practicing so far. \n",
    "\n",
    "Now it is time to write the functions that will actually be running on the robot (in simulation or on the physical one). \n",
    "\n",
    "You will write two functions:\n",
    "\n",
    "1. A function that calculates the rotation of a wheel given a message from the wheel encoders and the previous number of ticks measured;\n",
    "\n",
    "2. The actual odometry function, that will receive as inputs the kinematic model parameters, the pose estimate at the previous iteration, and the rotation of each wheel. The initial position is assumed to be $q_0 = [0,0,0]^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the rotation of each wheel\n",
    "\n",
    "Implement the function `delta_phi` inside the file [odometry_activity.py](../../packages/solution/odometry_activity.py).\n",
    "\n",
    "This function should output the wheel rotation (in radians) since last measurements, receiving as input the current and previous update wheel encoder readings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the odometry\n",
    "\n",
    "Implement the function `pose_estimation` inside the file [odometry_activity.py](../../packages/solution/odometry_activity.py).\n",
    "This function computes the `(x, y, theta)` estimate by aggregating computed wheel rotations and the (known) geometry of the robot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the `pose_estimation()` function\n",
    "\n",
    "Unit tests are useful to check if a piece of code does its intended job. Although the interaction of different functions might yield surprises even when each function produces the expected outcome, it is good pratice to test them in isolation before prime time! These are called \"unit tests\", and:\n",
    "\n",
    "> If it ain't tested, it's broken.\n",
    ">\n",
    "> --Roboticists, level 9\n",
    "\n",
    "Let's see if the function you wrote above passes the following test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/vincent/duckietown-lx/modcon/notebooks/04-Odometry/odometry_activity.ipynb Cell 29\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/duckietown-lx/modcon/notebooks/04-Odometry/odometry_activity.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtests\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39munit_test\u001b[39;00m \u001b[39mimport\u001b[39;00m UnitTestOdometry\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vincent/duckietown-lx/modcon/notebooks/04-Odometry/odometry_activity.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m packages\u001b[39m.\u001b[39msolution\u001b[39m.\u001b[39modometry_activity \u001b[39mimport\u001b[39;00m \u001b[39mpose_estimation\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/duckietown-lx/modcon/notebooks/04-Odometry/odometry_activity.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# UnitTestOdometry tests the `pose_estimation` function defined in odometry_activity.py.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/duckietown-lx/modcon/notebooks/04-Odometry/odometry_activity.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# The test is successful if you get a circle in the plot. \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/duckietown-lx/modcon/notebooks/04-Odometry/odometry_activity.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Anything different from a circle indicated that the odometry function has something wrong.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vincent/duckietown-lx/modcon/notebooks/04-Odometry/odometry_activity.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m UnitTestOdometry(R, baseline_wheel2wheel, pose_estimation)\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from tests.unit_test import UnitTestOdometry\n",
    "\n",
    "from . packages.solution.odometry_activity import pose_estimation\n",
    "\n",
    "# UnitTestOdometry tests the `pose_estimation` function defined in odometry_activity.py.\n",
    "# The test is successful if you get a circle in the plot. \n",
    "# Anything different from a circle indicated that the odometry function has something wrong.\n",
    "\n",
    "UnitTestOdometry(R, baseline_wheel2wheel, pose_estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A successful test will yield something similar to this: \n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/UnitTestValidation-2022.png\" width=\"800\" alt=\"successful-test-odometry\"></p>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "source": [
    "# ðŸ’» ðŸš™ Run the Activity\n",
    "\n",
    "Let's now see how the odometry is working in pratice. \n",
    "\n",
    "ðŸ’» ðŸš™ The first objective of this activity is to run the scripts you just wrote on a simulated and real robot, and see how they perform. \n",
    "\n",
    "ðŸ’¡ The second objective is reflecting on the outcome and trying to have the theory agree with your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’» Running the odometry in simulation\n",
    "\n",
    "1. Open a terminal on your computer, navigate to `/duckietown-lx/modcon/` and type \n",
    "\n",
    "       dts code build\n",
    "\n",
    "\n",
    "2. Wait for the build to finish, then type:\n",
    "\n",
    "       dts code workbench --sim\n",
    "\n",
    "\n",
    "3. Open VNC on you browser. \n",
    "\n",
    "4. Double-click on the \"Odometry\" icon on the Desktop\n",
    "\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/odometry_icon.png\" width=\"100\" alt=\"test-odometry-icon\"></p>  \n",
    "\n",
    "You will see three things opening: \n",
    "\n",
    "- a terminal\n",
    "- a pre-configured RVIZ window\n",
    "- a virtual joystick\n",
    "\n",
    "<figure>\n",
    "  <div style=\"text-align:center;\">\n",
    "  <img src=\"../../assets/images/odometry/od-sim-startup.png\" width=\"400\">\n",
    "  <p>Starting the Odometry activity.</p>\n",
    "  </div>\n",
    "</figure>\n",
    "\n",
    "In the RVIZ window you will see what your robot sees, and a reference frame in the gridmap. That frame represents the position and orientation of your robot, calculated _according to the `pose_estimation` and `delta_phi` functions written above_ (they are beliefs, not \"real\" states).\n",
    "\n",
    "**Note**: it may take some time (>30s) for the images and the odometry to appear, depending on the specifications of your host machine.  \n",
    "\n",
    "Tips: \n",
    "\n",
    "    - You can change the graphical settings of the reference frame (bigger, shorter, more or less frequently updated, etc.) through the Odometry > Shape options in the top left quadrant of the RVIZ window;\n",
    "    \n",
    "    - You can press `Alt` while clicking and dragging anywhere in the RVIZ terminal to move the window;\n",
    "    \n",
    "    - VNC opens with the resolution of your browser window when you launch it. If things look crammed, put your browser in full screen and re-copy and paste the URL. \n",
    "    \n",
    "    - The terminal on your computer will be streaming some debugging data, FYI. \n",
    "    \n",
    "5. Click on the virtual joystick and start driving. You will see the marker move too according to the wheel encoder data that the robot is receiving. You can monitor these (and other) messages by following the procedure learned in the [wheel encoders tutorial](../03-Wheel-Encoders-Tutorial/wheel_encoders_tutorial.ipynb). \n",
    "\n",
    "6. Drive as you wish (don't crash or you will have to restart!); we suggest doing a loop. Get back to the initial position and look at the resulting odometry. Is your robot's _belief_ accurate? Why, or why not? \n",
    "\n",
    "7. When you are satisfied with your experience and your odometry, `Ctrl-C` the terminal on your computer to stop VNC, or `Ctrl-C` your open terminal in VNC to go back to the desktop. \n",
    "\n",
    "Do you want to modify your odometry functions before proceeding? Change the cells above, `Ctrl-S` to save the page, and re-launch `dts code workbench --sim`. \n",
    "\n",
    "<!--\n",
    "<p style=\"text-align:center;\"><img src=\"../../assets/images/odometry/sim-odom-complete.png\" width=\"500\" alt=\"sim-odometry-complete\"></p> \n",
    "-->\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "        <div style=\"text-align:center;\">\n",
    "            <img src=\"../../assets/images/odometry/sim-odom-complete.png\" width=\"300\" />\n",
    "            <img src=\"../../assets/images/odometry/od-sim-tour.png\" width=\"300\" />\n",
    "            <p>Odometry with different markers on different loops.</p>\n",
    "        </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have a robot, you can now proceed to the [PID control activity](../05-PID-Control/PID_controller.ipynb). If you have a robot instead, buckle your Duckies up and continue reading, it's time to have some more fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš™ Running the odometry activity on the Duckiebot \n",
    "\n",
    "The procedure for running this activity on your Duckiebot is very similar to above, and the same tips apply. \n",
    "\n",
    "0. Make sure your Duckiebot is powered on, charged, and connected to the network. Moreover, make sure you have calibrated your robots kinematic parameters. \n",
    "\n",
    "1. Computer -> Open terminal\n",
    "\n",
    "        dts code build\n",
    "        \n",
    "        dts code workbench -b ROBOTNAME  \n",
    "\n",
    "\n",
    "2. Open VNC on you browser. \n",
    "\n",
    "3. Double-click on the \"Odometry\" icon on the Desktop \n",
    "\n",
    "You will see three things opening: \n",
    "\n",
    "- a terminal\n",
    "- a pre-configured RVIZ window\n",
    "- a virtual joystick\n",
    "\n",
    "In the RVIZ window you will see what your robot sees, and a marker in the gridmap. That reference frame represents the position and orientation of your robot _according to the `pose_estimation` and `delta_phi` functions written above_.\n",
    "    \n",
    "4. Click on the virtual joystick and start driving. You will see the marker move too according to the wheel encoder data that the robot is receiving. You can monitor these (and other) messages by following the procedure learned in the [wheel encoders tutorial](../03-Wheel-Encoders-Tutorial/wheel_encoders_tutorial.ipynb). \n",
    "\n",
    "5. Drive as you wish. We suggest driving in your Duckietown for two reasons: (a) you should have calibrated the gain of your motors so not to slip and (b) you will have a reference of the approximate driven path. Or you can drive around your house; or do both. Whatever you do, get back to the initial position (approximately) and look at the resulting odometry. Is your robot's _belief_ accurate? Why? \n",
    "\n",
    "6. When you are satisfied with your experience and your odometry, `Ctrl-C` the terminal on your computer to stop VNC, or `Ctrl-C` your open terminal in VNC to go back to the desktop. \n",
    "\n",
    "Do you want to modify your odometry functions before proceeding? Update the `pose_estimation` and `delta_phi` functions and re-launch `dts code workbench -b ROBOTNAME`. \n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "        <div style=\"text-align:center;\">\n",
    "            <img src=\"../../assets/images/odometry/odometry-real-2.png\" width=\"300\" alt=\"successful-test-odometry-real\" />\n",
    "            <img src=\"../../assets/images/odometry/less-good-odometry.png\" width=\"300\" />\n",
    "            <p>DB21 Duckiebot good and less good odometries.</p>\n",
    "        </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš™ Improving on the results\n",
    "\n",
    "There are many factor that affect the odometry and cause a drift over time. Although that is unavoidable, having an accurate estimate of the odometry parameters of the robot ($R$, $L$) will help. To improve your results above, modify your kinematic calibration parameters and try again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Reflecting on the experience\n",
    "\n",
    "The first thing you should have noticed is if your odometry made any sense at all. Did your motion reconstruction follow the actual driving? \n",
    "\n",
    "Even if your equations were correct, how accurate was the reconstruction? In the short run vs. the long run? Why? \n",
    "\n",
    "Try driving several loops (you can set how many arrows will be shown, reduce the number to avoid a big mess). Does it get better or worse? Why? \n",
    "\n",
    "Did you notice anything different in the robot movement vs. the model we made? For example? \n",
    "\n",
    "On the Duckiebot, how will your odometry change if you tweak you kinematics parameters? Can you get it to do better? \n",
    "\n",
    "Did you notice any difference between the real world and the simulation? Why do you think that is the case? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you just gave your robot the ability to _represent_ itself in the world. It's kind of, nearly, as if it started thinking (or not?)! You can now proceed to the next activity: designing a [PID controller for heading control](../05-PID-Control/PID_controller.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
